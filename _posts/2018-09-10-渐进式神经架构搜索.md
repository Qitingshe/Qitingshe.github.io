---
layout:		post
title:		渐进式神经架构搜索
subtitle:	Progressive Neural Architecture Search
date:		2018-09-10
author:		QITINGSHE
header-img:	img/post-bg-swift.jpg
catalog: true
tags:
    - 络模型优化
---

# 论文工作

本文提出学习CNN结构的新方法，相比于现在的强化学习和遗传算法，它更有效率。本文采用序列模型优化SMBO（sequential model-based optimization）策略，按**复杂度增大**的顺序来搜索架构，同时还学习一个**代理模型**来引导在结构空间的搜索行为。和最新的RL方法相比效率要高5倍，学习到的结构在CIFAR-10和ImageNet上可以达到当前最好。

本文主要采用的方法有一下几种：

- 进一步降低模型的搜索空间
- 按复杂度逐步训练网络
- 使用启发式搜索来选择要训练的模型结构，这样降低了需要训练的模型数量



最近出现许多自动学习好的神经网络架构工作，很多都是以下两个方法：

- 进化算法（EA）：每个神经网络结构都编码为一个字符串，在搜索过程中使用随机突变和重组字符串，然后对每个搜索到的模型做训练并在验证集上做评估，最好的模型称为"children"
- 强化学习（RL）：agent执行一系列行为，以此来指定模型架构，然后经过训练和评估返回一个reward，用于更新RNN 控制器。

虽然 EA和RL都有能力得到比手动设计模型更好的架构，但他们的计算量都不敢恭维。所以在本文中我们介绍一种更好的方法来学习CNN架构，计算量降低5倍。

# 未完待续

